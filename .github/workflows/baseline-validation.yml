name: Baseline Validation

on:
  pull_request:
    branches: [main, develop]
    paths:
      - 'src/**'
      - 'baseline/**'
      - 'tests/**'
      - 'package.json'
      - 'bun.lock'
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      full_validation:
        description: 'Run full validation suite'
        required: false
        default: 'false'
        type: boolean

env:
  BUN_VERSION: '1.0'
  NODE_VERSION: '20'

jobs:
  # Fast validation for quick feedback
  quick-validation:
    name: Quick Validation (< 2min)
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_continue: ${{ steps.quick-check.outputs.should_continue }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.bun/install/cache
            node_modules
            tests/node_modules
          key: ${{ runner.os }}-bun-${{ hashFiles('**/bun.lock', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-bun-
            
      - name: Install dependencies
        run: |
          bun install
          cd tests && bun install
          
      - name: Quick structure validation
        id: quick-check
        run: |
          cd tests
          
          # Run fast structural tests
          echo "Running structural validation..."
          bun test tests/structural/ --timeout 30000
          
          # Check if baseline files exist
          echo "Checking baseline integrity..."
          bun run -e "
            import { promises as fs } from 'fs';
            import { TEST_CONFIG } from './config.ts';
            
            for (const file of TEST_CONFIG.validation.compareFiles) {
              const path = \`\${TEST_CONFIG.baseline.todo}/\${file}\`;
              try {
                await fs.access(path);
                console.log(\`✅ \${file}\`);
              } catch {
                console.error(\`❌ Missing baseline file: \${file}\`);
                process.exit(1);
              }
            }
            console.log('All baseline files present');
          "
          
          # Set output for next jobs
          echo "should_continue=true" >> $GITHUB_OUTPUT
          
      - name: Generate quick report
        if: always()
        run: |
          cd tests
          bun run tools/reporter.ts --quick > quick-report.md
          
      - name: Comment PR (Quick Results)
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let comment = '## 🧪 Quick Validation Results\n\n';
            
            if ('${{ steps.quick-check.outcome }}' === 'success') {
              comment += '✅ **Structural validation passed** - proceeding with full validation\n\n';
            } else {
              comment += '❌ **Structural validation failed** - please fix basic issues first\n\n';
              comment += '### Issues\n';
              comment += '- Check that all baseline files exist\n';
              comment += '- Verify file structure matches expectations\n';
              comment += '- Run `bun run test:structure` locally\n\n';
            }
            
            comment += '⏳ Full validation is running...\n';
            
            // Find existing comment and update or create new
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(c => 
              c.body.includes('🧪 Quick Validation Results') || 
              c.body.includes('🧪 Baseline Validation Results')
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  # Comprehensive validation
  full-validation:
    name: Full Validation
    runs-on: ubuntu-latest
    needs: quick-validation
    if: needs.quick-validation.outputs.should_continue == 'true'
    timeout-minutes: 15
    
    strategy:
      matrix:
        validation-type: [content, types, functional]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}
          
      - name: Restore dependencies cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.bun/install/cache
            node_modules
            tests/node_modules
          key: ${{ runner.os }}-bun-${{ hashFiles('**/bun.lock', '**/package.json') }}
          
      - name: Install dependencies
        run: |
          bun install
          cd tests && bun install
          
      - name: Run validation (${{ matrix.validation-type }})
        run: |
          cd tests
          case "${{ matrix.validation-type }}" in
            content)
              echo "Running content validation..."
              bun test tests/content/ --timeout 120000
              ;;
            types)
              echo "Running type safety validation..."
              bun test tests/types/ --timeout 180000
              ;;
            functional)
              echo "Running functional validation..."
              bun test tests/functional/ --timeout 300000
              ;;
          esac
          
      - name: Generate validation report
        if: always()
        run: |
          cd tests
          mkdir -p reports
          bun run tools/reporter.ts \
            --category ${{ matrix.validation-type }} \
            --output reports/${{ matrix.validation-type }}-report.json
            
      - name: Upload validation artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: validation-reports-${{ matrix.validation-type }}
          path: tests/reports/
          retention-days: 7

  # Integration testing with real Next.js apps
  integration-validation:
    name: Integration Validation  
    runs-on: ubuntu-latest
    needs: quick-validation
    if: needs.quick-validation.outputs.should_continue == 'true'
    timeout-minutes: 20
    
    strategy:
      matrix:
        next-version: ['13.5', '14.0']
        node-version: ['18', '20']
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}
          
      - name: Create test Next.js app
        run: |
          cd tests
          
          # Create test app with specific Next.js version
          npx create-next-app@latest test-app-${{ matrix.next-version }} \
            --typescript \
            --app \
            --no-eslint \
            --no-tailwind \
            --no-src-dir
            
          cd test-app-${{ matrix.next-version }}
          
          # Install specific Next.js version
          bun add next@${{ matrix.next-version }} react react-dom
          bun add -d @types/react @types/node typescript
          
      - name: Test generator integration
        run: |
          cd tests/test-app-${{ matrix.next-version }}
          
          # Copy test schema
          cp ../fixtures/test-schema.prisma prisma/schema.prisma
          
          # Install and run generator
          bun add file:../../.. 
          bun add prisma @prisma/client jotai
          
          npx prisma generate
          
          # Verify generated files exist
          test -f generated/flow/index.ts || exit 1
          test -f generated/flow/todo/actions.ts || exit 1
          test -f generated/flow/todo/hooks.ts || exit 1
          
          echo "✅ Generator integration successful"
          
      - name: Test app compilation
        run: |
          cd tests/test-app-${{ matrix.next-version }}
          
          # Test TypeScript compilation
          npx tsc --noEmit
          
          # Test Next.js build (without running)
          timeout 300 npm run build || {
            echo "Build timeout or failed"
            exit 1
          }
          
          echo "✅ App compilation successful"

  # Performance benchmarking
  performance-validation:
    name: Performance Validation
    runs-on: ubuntu-latest
    needs: quick-validation
    if: needs.quick-validation.outputs.should_continue == 'true'
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}
          
      - name: Install dependencies
        run: |
          bun install
          cd tests && bun install
          
      - name: Run performance benchmarks
        run: |
          cd tests
          
          echo "🚀 Running performance benchmarks..."
          
          # Benchmark code generation
          time_start=$(date +%s%N)
          bun run utils/generator.ts --benchmark
          time_end=$(date +%s%N)
          generation_time=$(( (time_end - time_start) / 1000000 ))
          
          echo "Generation time: ${generation_time}ms"
          
          # Benchmark TypeScript compilation
          time_start=$(date +%s%N)
          bun run utils/typescript-compiler.ts --benchmark
          time_end=$(date +%s%N)
          compilation_time=$(( (time_end - time_start) / 1000000 ))
          
          echo "Compilation time: ${compilation_time}ms"
          
          # Store results
          echo "GENERATION_TIME=${generation_time}" >> $GITHUB_ENV
          echo "COMPILATION_TIME=${compilation_time}" >> $GITHUB_ENV
          
      - name: Check performance thresholds
        run: |
          # Set performance thresholds (ms)
          MAX_GENERATION=10000  # 10 seconds
          MAX_COMPILATION=30000  # 30 seconds
          
          if [ "$GENERATION_TIME" -gt "$MAX_GENERATION" ]; then
            echo "❌ Generation time exceeded threshold: ${GENERATION_TIME}ms > ${MAX_GENERATION}ms"
            exit 1
          fi
          
          if [ "$COMPILATION_TIME" -gt "$MAX_COMPILATION" ]; then
            echo "❌ Compilation time exceeded threshold: ${COMPILATION_TIME}ms > ${MAX_COMPILATION}ms"  
            exit 1
          fi
          
          echo "✅ Performance within acceptable limits"

  # Final report generation
  generate-final-report:
    name: Generate Final Report
    runs-on: ubuntu-latest
    needs: [quick-validation, full-validation, integration-validation, performance-validation]
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}
          
      - name: Download all artifacts
        uses: actions/download-artifact@v3
        with:
          path: artifacts/
          
      - name: Install dependencies
        run: |
          cd tests && bun install
          
      - name: Generate comprehensive report
        run: |
          cd tests
          
          # Combine all validation results
          bun run tools/reporter.ts \
            --combine-artifacts ../artifacts/ \
            --output reports/final-report.html \
            --format html
            
          # Generate markdown summary for PR
          bun run tools/reporter.ts \
            --combine-artifacts ../artifacts/ \
            --output reports/pr-summary.md \
            --format markdown
            
      - name: Upload final reports
        uses: actions/upload-artifact@v3
        with:
          name: final-validation-report
          path: tests/reports/
          retention-days: 30
          
      - name: Comment PR (Final Results)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'tests/reports/pr-summary.md';
            
            let comment = '';
            try {
              comment = fs.readFileSync(path, 'utf8');
            } catch (error) {
              comment = `## 🧪 Baseline Validation Results
              
❌ **Report generation failed**

Error: ${error.message}

Please check the workflow logs for details.`;
            }
            
            // Find existing comment and update
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(c => 
              c.body.includes('🧪 Quick Validation Results') || 
              c.body.includes('🧪 Baseline Validation Results')
            );
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
            
      - name: Set job status
        run: |
          # Determine overall status based on previous jobs
          QUICK_STATUS="${{ needs.quick-validation.result }}"
          VALIDATION_STATUS="${{ needs.full-validation.result }}"
          INTEGRATION_STATUS="${{ needs.integration-validation.result }}"
          PERFORMANCE_STATUS="${{ needs.performance-validation.result }}"
          
          if [[ "$QUICK_STATUS" != "success" ]]; then
            echo "❌ Quick validation failed"
            exit 1
          elif [[ "$VALIDATION_STATUS" != "success" ]]; then
            echo "❌ Full validation failed"
            exit 1  
          elif [[ "$INTEGRATION_STATUS" != "success" ]]; then
            echo "❌ Integration validation failed"
            exit 1
          elif [[ "$PERFORMANCE_STATUS" != "success" ]]; then
            echo "❌ Performance validation failed"
            exit 1
          else
            echo "✅ All validations passed"
          fi